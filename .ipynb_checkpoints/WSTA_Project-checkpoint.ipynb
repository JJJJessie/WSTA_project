{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Team Name:     XiaoJiLingGui\n",
    "\n",
    "Kaggle Login:  siqiguo\n",
    "\n",
    "Student Name:  Siqi Guo\n",
    "\n",
    "Student ID:    743053\n",
    "\n",
    "Kaggle Login: \n",
    "\n",
    "Student Name:\n",
    "\n",
    "Student ID: \n",
    "\n",
    "Python version used: 2.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from math import log\n",
    "from collections import defaultdict, Counter\n",
    "import requests, tarfile\n",
    "import json\n",
    "\n",
    "stopwords = set(nltk.corpus.stopwords.words('english')) # wrap in a set() (see below)\n",
    "stemmer = nltk.stem.PorterStemmer() \n",
    "sent_segmenter = nltk.data.load('tokenizers/punkt/english.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Extract the document details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.41096876688059836), (2, 0.15006844133204789)]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def select_document(fname, docid):\n",
    "    with open(fname) as json_data:\n",
    "        infile = json.load(json_data)\n",
    "        for doc in infile:\n",
    "            if doc['docid'] == docid:\n",
    "                text = doc['text']\n",
    "    return text\n",
    "\n",
    "def parse_paragraphs(text):\n",
    "    identifier = 0\n",
    "    for para in text:\n",
    "        yield (identifier, para)\n",
    "        identifier += 1\n",
    "\n",
    "def extract_terms(para):\n",
    "    terms = set()\n",
    "    for token in nltk.word_tokenize(para):\n",
    "        if token not in stopwords: # 'in' and 'not in' opera]tions are much faster over sets that lists\n",
    "            terms.add(stemmer.stem(token.lower()))\n",
    "    return terms\n",
    "\n",
    "def extract_term_freqs(para):\n",
    "    tfs = Counter()\n",
    "    for token in para:\n",
    "        if token not in stopwords: # 'in' and 'not in' operations are much faster over sets that lists\n",
    "            tfs[stemmer.stem(token.lower())] += 1\n",
    "    return tfs\n",
    "\n",
    "def compute_para_freqs(para_term_freqs):\n",
    "    pfs = Counter()\n",
    "    for tfs in para_term_freqs.values():\n",
    "        for term in tfs.keys():\n",
    "            pfs[term] += 1\n",
    "    return pfs\n",
    "\n",
    "def get_index(para_term_freqs, para_freqs, M):\n",
    "    vsm_inverted_index = defaultdict(list)\n",
    "    for pid, term_freqs in para_term_freqs.items():\n",
    "        N = sum(term_freqs.values())\n",
    "        length = 0\n",
    "\n",
    "        # find tf*idf values and accumulate sum of squares \n",
    "        tfidf_values = []\n",
    "        for term, count in term_freqs.items():\n",
    "            tfidf = float(count) / N * log(M / float(para_freqs[term]))\n",
    "            tfidf_values.append((term, tfidf))\n",
    "            length += tfidf ** 2\n",
    "\n",
    "        # normalise documents by length and insert into index\n",
    "        length = length ** 0.5\n",
    "        for term, tfidf in tfidf_values:\n",
    "            # note the inversion of the indexing, to be term -> (doc_id, score)\n",
    "            vsm_inverted_index[term].append([pid, tfidf / length])\n",
    "\n",
    "    # ensure posting lists are in sorted order (less important here cf above)\n",
    "    for term, pids in vsm_inverted_index.items():\n",
    "        pids.sort()\n",
    "    return vsm_inverted_index\n",
    "    \n",
    "def query_vsm(query, index, k=2):\n",
    "    accumulator = Counter()\n",
    "    for term in query:\n",
    "        postings = index[term]\n",
    "        for pid, weight in postings:\n",
    "            accumulator[pid] += weight\n",
    "    return accumulator.most_common(k)\n",
    "\n",
    "def get_freq_dict(raw_paras):\n",
    "    paras = {}\n",
    "    for pid, p in raw_paras:\n",
    "        terms = extract_terms(p)\n",
    "        paras[pid] = terms\n",
    "\n",
    "    para_term_freqs = {}\n",
    "    for pid, terms in paras.items():\n",
    "        term_freqs = extract_term_freqs(terms)\n",
    "        para_term_freqs[pid] = term_freqs\n",
    "    M = len(para_term_freqs)\n",
    "    return paras, para_term_freqs, M\n",
    "\n",
    "docfname = 'project_files/documents.json'\n",
    "text = select_document(docfname, 0)\n",
    "raw_paras = list(parse_paragraphs(text))\n",
    "\n",
    "paras, para_term_freqs, M = get_freq_dict(raw_paras)\n",
    "para_freqs = compute_para_freqs(para_term_freqs)\n",
    "results = query_vsm([stemmer.stem(term.lower()) for term in \"constant element particle\".split()], get_index(para_term_freqs, para_freqs, M))\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, u'First recognized in 1900 by Max Planck, it was originally the proportionality constant between the minimal increment of energy, E, of a hypothetical electrically charged oscillator in a cavity that contained black body radiation, and the frequency, f, of its associated electromagnetic wave. In 1905 the value E, the minimal energy increment of a hypothetical oscillator, was theoretically associated by Einstein with a \"quantum\" or minimal element of the energy of the electromagnetic wave itself. The light quantum behaved in some respects as an electrically neutral particle, as opposed to an electromagnetic wave. It was eventually called the photon.')\n"
     ]
    }
   ],
   "source": [
    "print(raw_paras[results[0][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
